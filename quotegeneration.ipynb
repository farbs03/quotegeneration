{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "quotegeneration.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNXIC6adPuWViMICv0nnYrJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/farbs03/quotegeneration/blob/master/quotegeneration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKefAFvHKTBZ"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "\n",
        "import numpy as np \n",
        "import re\n",
        "import sys"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltrB-AUlKUjf"
      },
      "source": [
        "quotes = []\n",
        "for page in range(1, 101):\n",
        "    content = requests.get(f\"https://www.goodreads.com/quotes?page={page}\")\n",
        "    soup = BeautifulSoup(content.text, 'html.parser')\n",
        "    for quote in soup.find_all('div', attrs={'class': \"quoteText\"}):\n",
        "        text = quote.text.split('―')[0].split('\\n')[1].split(\"      \")[1]\n",
        "        quotes.append(text[1:len(text) - 2])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHAVYinzLXU3",
        "outputId": "e65d7b2a-fc35-4f36-82ca-396b72182007"
      },
      "source": [
        "len(quotes)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2970"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJgVwmCdLn0K"
      },
      "source": [
        "with open(\"quotes.txt\", \"w\") as text:\n",
        "  for quote in quotes:\n",
        "    text.write(quote)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSQ60gZqMTMC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e61d5ba8-794d-4c26-c696-71a0feb82026"
      },
      "source": [
        "\"\"\"\n",
        "Install the GPT-2 fine-tuning library\n",
        "\"\"\"\n",
        "\n",
        "!pip3 install -q gpt-2-simple\n",
        "!pip3 install gast==0.2.2\n",
        "!pip3 install -q tensorflow==1.15"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gast==0.2.2\n",
            "  Downloading gast-0.2.2.tar.gz (10 kB)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-py3-none-any.whl size=7554 sha256=5a5169a3b920294e6e25db77dfda0b2eb6e79bccafee2bf9b00b57efe081776b\n",
            "  Stored in directory: /root/.cache/pip/wheels/21/7f/02/420f32a803f7d0967b48dd823da3f558c5166991bfd204eef3\n",
            "Successfully built gast\n",
            "Installing collected packages: gast\n",
            "  Attempting uninstall: gast\n",
            "    Found existing installation: gast 0.4.0\n",
            "    Uninstalling gast-0.4.0:\n",
            "      Successfully uninstalled gast-0.4.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.6.0 requires gast==0.4.0, but you have gast 0.2.2 which is incompatible.\n",
            "tensorflow-probability 0.13.0 requires gast>=0.3.2, but you have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Successfully installed gast-0.2.2\n",
            "\u001b[K     |████████████████████████████████| 412.3 MB 19 kB/s \n",
            "\u001b[K     |████████████████████████████████| 503 kB 48.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.8 MB 52.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 50 kB 5.3 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "kapre 0.3.5 requires tensorflow>=2.0.0, but you have tensorflow 1.15.0 which is incompatible.\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1ViO7xu9uIb",
        "outputId": "5bb22a95-34bf-4455-a8bc-8260ed1c83db"
      },
      "source": [
        "import io\n",
        "import os\n",
        "import pickle\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "from zipfile import ZipFile\n",
        "import gpt_2_simple as gpt2\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.15.0\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pd81ip1z98ja",
        "outputId": "7b38b5b2-d5d6-4208-a8bd-09b44ad0e3f6"
      },
      "source": [
        "model_name = \"124M\"\n",
        "print(f\"Downloading {model_name} model...\")\n",
        "gpt2.download_gpt2(model_name = model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading 124M model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 113Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 7.05Mit/s]\n",
            "Fetching hparams.json: 1.05Mit [00:00, 617Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:07, 68.4Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 274Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 10.6Mit/s]                                                \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 13.3Mit/s]                                                      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IAX7gf5u_lSZ",
        "outputId": "7a40f7a1-6936-436c-fd14-f2033aa627cb"
      },
      "source": [
        "tf.reset_default_graph()\n",
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.finetune(sess, \"quotes.txt\", model_name=model_name, steps=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n",
            "Loading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset has 109829 tokens\n",
            "Training...\n",
            "[1 | 12.71] loss=3.77 avg=3.77\n",
            "[2 | 16.94] loss=3.77 avg=3.77\n",
            "[3 | 21.17] loss=3.72 avg=3.75\n",
            "[4 | 25.40] loss=3.57 avg=3.71\n",
            "[5 | 29.63] loss=3.56 avg=3.68\n",
            "[6 | 33.86] loss=3.62 avg=3.67\n",
            "[7 | 38.09] loss=3.48 avg=3.64\n",
            "[8 | 42.34] loss=3.51 avg=3.62\n",
            "[9 | 46.59] loss=3.46 avg=3.60\n",
            "[10 | 50.83] loss=3.51 avg=3.59\n",
            "[11 | 55.08] loss=3.38 avg=3.57\n",
            "[12 | 59.34] loss=3.49 avg=3.57\n",
            "[13 | 63.60] loss=3.32 avg=3.55\n",
            "[14 | 67.86] loss=3.50 avg=3.54\n",
            "[15 | 72.12] loss=3.24 avg=3.52\n",
            "[16 | 76.38] loss=3.43 avg=3.52\n",
            "[17 | 80.64] loss=3.30 avg=3.50\n",
            "[18 | 84.91] loss=3.53 avg=3.50\n",
            "[19 | 89.17] loss=3.34 avg=3.49\n",
            "[20 | 93.43] loss=3.47 avg=3.49\n",
            "[21 | 97.68] loss=3.29 avg=3.48\n",
            "[22 | 101.95] loss=3.40 avg=3.48\n",
            "[23 | 106.21] loss=3.25 avg=3.47\n",
            "[24 | 110.49] loss=3.32 avg=3.46\n",
            "[25 | 114.75] loss=3.25 avg=3.45\n",
            "[26 | 119.03] loss=3.15 avg=3.44\n",
            "[27 | 123.30] loss=3.22 avg=3.43\n",
            "[28 | 127.56] loss=3.23 avg=3.42\n",
            "[29 | 131.84] loss=3.32 avg=3.42\n",
            "[30 | 136.12] loss=3.43 avg=3.42\n",
            "[31 | 140.39] loss=3.25 avg=3.41\n",
            "[32 | 144.66] loss=3.23 avg=3.40\n",
            "[33 | 148.93] loss=3.20 avg=3.40\n",
            "[34 | 153.20] loss=3.18 avg=3.39\n",
            "[35 | 157.47] loss=3.22 avg=3.38\n",
            "[36 | 161.74] loss=3.12 avg=3.37\n",
            "[37 | 166.01] loss=3.38 avg=3.38\n",
            "[38 | 170.28] loss=2.99 avg=3.36\n",
            "[39 | 174.55] loss=3.12 avg=3.36\n",
            "[40 | 178.82] loss=3.11 avg=3.35\n",
            "[41 | 183.08] loss=2.52 avg=3.32\n",
            "[42 | 187.36] loss=2.70 avg=3.31\n",
            "[43 | 191.62] loss=3.12 avg=3.30\n",
            "[44 | 195.89] loss=2.86 avg=3.29\n",
            "[45 | 200.17] loss=2.98 avg=3.28\n",
            "[46 | 204.43] loss=3.15 avg=3.28\n",
            "[47 | 208.71] loss=3.01 avg=3.27\n",
            "[48 | 212.96] loss=2.82 avg=3.26\n",
            "[49 | 217.23] loss=3.14 avg=3.25\n",
            "[50 | 221.49] loss=3.06 avg=3.25\n",
            "[51 | 225.74] loss=2.83 avg=3.24\n",
            "[52 | 230.01] loss=2.76 avg=3.23\n",
            "[53 | 234.29] loss=2.86 avg=3.22\n",
            "[54 | 238.55] loss=3.08 avg=3.21\n",
            "[55 | 242.81] loss=3.04 avg=3.21\n",
            "[56 | 247.07] loss=3.14 avg=3.21\n",
            "[57 | 251.41] loss=2.99 avg=3.20\n",
            "[58 | 255.68] loss=3.09 avg=3.20\n",
            "[59 | 259.94] loss=2.94 avg=3.20\n",
            "[60 | 264.21] loss=2.79 avg=3.19\n",
            "[61 | 268.47] loss=2.81 avg=3.18\n",
            "[62 | 272.74] loss=2.87 avg=3.17\n",
            "[63 | 277.00] loss=3.01 avg=3.17\n",
            "[64 | 281.26] loss=2.68 avg=3.16\n",
            "[65 | 285.53] loss=2.86 avg=3.15\n",
            "[66 | 289.95] loss=2.52 avg=3.14\n",
            "[67 | 294.22] loss=2.79 avg=3.13\n",
            "[68 | 298.48] loss=2.82 avg=3.13\n",
            "[69 | 302.74] loss=2.83 avg=3.12\n",
            "[70 | 307.01] loss=2.73 avg=3.11\n",
            "[71 | 311.28] loss=2.94 avg=3.11\n",
            "[72 | 315.55] loss=2.72 avg=3.10\n",
            "[73 | 319.82] loss=2.71 avg=3.09\n",
            "[74 | 324.09] loss=2.76 avg=3.09\n",
            "[75 | 328.35] loss=2.87 avg=3.08\n",
            "[76 | 332.62] loss=2.65 avg=3.07\n",
            "[77 | 336.89] loss=2.73 avg=3.07\n",
            "[78 | 341.15] loss=2.78 avg=3.06\n",
            "[79 | 345.41] loss=2.65 avg=3.06\n",
            "[80 | 349.66] loss=2.81 avg=3.05\n",
            "[81 | 353.95] loss=2.67 avg=3.04\n",
            "[82 | 358.21] loss=2.85 avg=3.04\n",
            "[83 | 362.48] loss=2.77 avg=3.04\n",
            "[84 | 366.74] loss=2.42 avg=3.03\n",
            "[85 | 371.00] loss=2.52 avg=3.02\n",
            "[86 | 375.27] loss=2.36 avg=3.00\n",
            "[87 | 379.53] loss=2.21 avg=2.99\n",
            "[88 | 383.81] loss=2.92 avg=2.99\n",
            "[89 | 388.08] loss=2.47 avg=2.98\n",
            "[90 | 392.34] loss=2.51 avg=2.97\n",
            "[91 | 396.61] loss=2.41 avg=2.96\n",
            "[92 | 400.88] loss=2.49 avg=2.96\n",
            "[93 | 405.14] loss=2.65 avg=2.95\n",
            "[94 | 409.41] loss=2.30 avg=2.94\n",
            "[95 | 413.67] loss=2.32 avg=2.93\n",
            "[96 | 417.93] loss=2.28 avg=2.92\n",
            "[97 | 422.21] loss=2.41 avg=2.91\n",
            "[98 | 426.47] loss=2.33 avg=2.90\n",
            "[99 | 430.75] loss=2.08 avg=2.89\n",
            "[100 | 435.01] loss=2.30 avg=2.88\n",
            "Saving checkpoint/run1/model-100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvQmTuWlFyBC"
      },
      "source": [
        "generated = []\n",
        "for i in range(20):\n",
        "    output = gpt2.generate(sess, length=30, return_as_list=True)[0]\n",
        "    generated.append(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pitr4uIHTPU2",
        "outputId": "5c47d30a-aa91-4920-d45d-7598b263dbb7"
      },
      "source": [
        "generated"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['And now the good news is that if you are doing well, and you are getting a lot of credit, and you are doing something really worthwhile,',\n",
              " \"How the hell do you know what you're doing?''I don't know,' he said, 'but I know what you're doing.' '\",\n",
              " \"The richest men in the history of the world are still trying to find a way to bend our heads in prayer, but they're not getting anywhere.\",\n",
              " 'Enchantment - Aura\\n\\nWhen enchanted creature dies, if enchanted creature is blocked by enchanted creature for any reason, destroy enchanted creature.Poss',\n",
              " \"I'm not sure if your parents were as agreeable as you seem. Or if they were. But you are not the sort of person you'll ever\",\n",
              " 'The people who live and work in our cities are not always the people who live and work. They are the people who are not busy in their day',\n",
              " \"A woman who has never had a boyfriend is never alone. She has to find someone who can take her somewhere. And if the guy isn't the\",\n",
              " 'The world was rocked by a major earthquake on Friday, the first major one-to-one earthquake in recorded history. The fault line broke, forming',\n",
              " \"I was just coming off a battle with my shoulder blades. What was I supposed to do? I'd just stabbed my shoulder. I'm not normal\",\n",
              " \"You can say that if you want to, but I've never found that 'cause it makes me weak and lonely. It makes me lonelyWhen I\",\n",
              " 'There are two kinds of women in our world—the pretty and the cuckoo. The pretty girl wants money and fame and is always the one',\n",
              " \"You can't sit with the wrong person and be unhappy for a long time. You need to change. You can't trust someone who doesn't understand\",\n",
              " 'My favorite thing in the world is someone who understands your feelings. You have to learn to walk a fine line between being sincere and being sincere in your',\n",
              " \"Game of Thrones is about sex, and it's not about letting go. It's about letting go of all the fears, all the expectations, and\",\n",
              " 'The last time I saw him was when he was trying to catch a train to London. It was a very strange day. He was staring out the',\n",
              " 'The first time I took my first breath, I was overcome with emotion. I could feel my lungs filling with air, my heart beating rapidly, but',\n",
              " \"He missed the bus, but he won't forget it. He won't forget the memories he never had of being with her or not liking her.\",\n",
              " \"If you're looking for a quick and fun escape, the library is your friend. The best way to do that is to find someone who can teach\",\n",
              " \"I'm a little overweight. I've never been bullied, I'm outgoing and outgoing. I'm sensitive, outgoing, and outgoing. I'm kind\",\n",
              " 'To remove the fat, you have to lean in. All the way to the bottom. You have to be able to lean in and out. You']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFL-7EIpW3Zk"
      },
      "source": [
        "for i in range(20):\n",
        "    output = gpt2.generate(sess, length=30, return_as_list=True)[0]\n",
        "    generated.append(output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGdAKwxEeYF-"
      },
      "source": [
        "readQuotes = []\n",
        "with open(\"gpt2quotes.txt\", \"r\") as gpt2quotes:\n",
        "  readQuotes = gpt2quotes.readlines()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpUoSd_lhJKd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dea8b370-be19-4b42-fe52-bc3d7eb360b8"
      },
      "source": [
        "readQuotes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['And now the good news is that if you are doing well, and you are getting a lot of credit, and you are doing something really worthwhile,\\n',\n",
              " \"How the hell do you know what you're doing?''I don't know,' he said, 'but I know what you're doing.' '\\n\",\n",
              " \"The richest men in the history of the world are still trying to find a way to bend our heads in prayer, but they're not getting anywhere.\\n\",\n",
              " 'Enchantment - Aura\\n',\n",
              " '\\n',\n",
              " 'When enchanted creature dies, if enchanted creature is blocked by enchanted creature for any reason, destroy enchanted creature.Poss\\n',\n",
              " \"I'm not sure if your parents were as agreeable as you seem. Or if they were. But you are not the sort of person you'll ever\\n\",\n",
              " 'The people who live and work in our cities are not always the people who live and work. They are the people who are not busy in their day\\n',\n",
              " \"A woman who has never had a boyfriend is never alone. She has to find someone who can take her somewhere. And if the guy isn't the\\n\",\n",
              " 'The world was rocked by a major earthquake on Friday, the first major one-to-one earthquake in recorded history. The fault line broke, forming\\n',\n",
              " \"I was just coming off a battle with my shoulder blades. What was I supposed to do? I'd just stabbed my shoulder. I'm not normal\\n\",\n",
              " \"You can say that if you want to, but I've never found that 'cause it makes me weak and lonely. It makes me lonelyWhen I\\n\",\n",
              " 'There are two kinds of women in our world—the pretty and the cuckoo. The pretty girl wants money and fame and is always the one\\n',\n",
              " \"You can't sit with the wrong person and be unhappy for a long time. You need to change. You can't trust someone who doesn't understand\\n\",\n",
              " 'My favorite thing in the world is someone who understands your feelings. You have to learn to walk a fine line between being sincere and being sincere in your\\n',\n",
              " \"Game of Thrones is about sex, and it's not about letting go. It's about letting go of all the fears, all the expectations, and\\n\",\n",
              " 'The last time I saw him was when he was trying to catch a train to London. It was a very strange day. He was staring out the\\n',\n",
              " 'The first time I took my first breath, I was overcome with emotion. I could feel my lungs filling with air, my heart beating rapidly, but\\n',\n",
              " \"He missed the bus, but he won't forget it. He won't forget the memories he never had of being with her or not liking her.\\n\",\n",
              " \"If you're looking for a quick and fun escape, the library is your friend. The best way to do that is to find someone who can teach\\n\",\n",
              " \"I'm a little overweight. I've never been bullied, I'm outgoing and outgoing. I'm sensitive, outgoing, and outgoing. I'm kind\\n\",\n",
              " 'To remove the fat, you have to lean in. All the way to the bottom. You have to be able to lean in and out. You\\n',\n",
              " \"I don't know how I got here, but I figured I'd be okay here if we didn't have a picnicThe only thing that can make\\n\",\n",
              " \"Let me begin by saying that I love my books. Like very much the whole family is my family. I'm not afraid of anybody, i.\\n\",\n",
              " 'Still loading...\\n',\n",
              " '\\n',\n",
              " 'A B C D E F G H I J K L M N O P Q R S T U V W X Y\\n',\n",
              " \"I can't get my emotions in order. They're all in my head. And it's awful because I can't get my emotions in orderI\\n\",\n",
              " 'How can we say good things when we are wrong? “When you don’t do something, it’s because you’\\n',\n",
              " \"I'm going to go into the game first, because I think it's going to be fun. I just want to see what it is. And\\n\",\n",
              " '\"I\\'m going to write a book,\" he said, \"and I want to get it out there.\" \"Books are for love,\" I said\\n',\n",
              " \"It's never too late to be kind. And sometimes, that's what kindness is all about. If you can do it, if you can come\\n\",\n",
              " \"He says that if there's one thing that I've learned in life, it's that if you let go, you can put things back together.\\n\",\n",
              " 'When you think about it, a lot of people will not want to go but one person will: it will be you. So, you start walking\\n',\n",
              " \"If you like your books, don't look for a book in a library that hasn't been written by someone with a better eye for tasteIf you\\n\",\n",
              " \"When I started buying Books, I didn't want to waste time on reading them. I wanted to spend my time doing what I was doing and not\\n\",\n",
              " 'I am one of the few mortals who can swallow the idea of death and live to be old enough to die of old ageOne of the great things\\n',\n",
              " \"It's not that a person is stupid. It's that they are a genius. I've got a reputation for being a genius. That's the\\n\",\n",
              " \"I've seen it all: how to stop someone who's doing a good thing, how to keep them in check, but never leaving them standing in\\n\",\n",
              " 'You must enter the characters with black color that stand out from the other characters\\n',\n",
              " '\\n',\n",
              " 'Message: * A friend wanted You must enter the characters with black\\n',\n",
              " 'First of all, I am sick of people saying things like, \"If you want to know what life is like, you\\'ve got to go out\\n',\n",
              " 'We are not responsible for translations, translations are translations - all translations are our thanksIf you want to make a difference in the world, make a difference\\n',\n",
              " 'Fireworks are a constant part of our lives. It is one of the most beautiful things I have ever seen; I am so sure it will come\\n',\n",
              " 'There are a number of reasons why a man may not be a good lover. One of them is that he is too busy keeping a secret to be\\n']"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ex6Av78iDTzg"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}